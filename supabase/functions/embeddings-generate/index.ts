/**
 * embeddings-generate — Central server-side embeddings service.
 *
 * Uses OpenRouter API (OpenAI-compatible) with text-embedding-3-large model.
 *
 * Security:
 *   - Requires x-internal-key header (INTERNAL_INGEST_KEY) OR valid Bearer JWT.
 *   - NEVER logs raw text — counts only.
 *
 * Input:  { texts: string[], model?: string, dimensions?: number }
 * Output: { vectors: number[][], model: string, usage: { total_tokens: number } }
 */

import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from "https://esm.sh/@supabase/supabase-js@2.91.1";

// ─── Config ────────────────────────────────────────────────────────────────
const OPENAI_BASE_URL = "https://api.openai.com/v1";
const DEFAULT_MODEL = "text-embedding-3-large";
const MAX_BATCH_SIZE = 100;
const MAX_CHARS_PER_TEXT = 32_000; // ~8k tokens
const MAX_RETRIES = 3;
const RETRY_DELAY_MS = 1_000;

// ─── CORS ──────────────────────────────────────────────────────────────────
const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers":
    "authorization, x-client-info, apikey, content-type, x-internal-key, " +
    "x-supabase-client-platform, x-supabase-client-platform-version, " +
    "x-supabase-client-runtime, x-supabase-client-runtime-version",
  "Access-Control-Allow-Methods": "POST, OPTIONS",
};

// ─── Auth guard ────────────────────────────────────────────────────────────
async function authenticate(req: Request): Promise<boolean> {
  // 1. Internal key (service-to-service)
  const internalKey = req.headers.get("x-internal-key");
  const expectedKey = Deno.env.get("INTERNAL_INGEST_KEY");
  if (internalKey && expectedKey && internalKey === expectedKey) {
    return true;
  }

  // 2. Bearer JWT (authenticated user / service role)
  const authHeader = req.headers.get("Authorization") ?? "";
  const token = authHeader.replace("Bearer ", "").trim();
  if (!token) return false;

  const supabaseUrl = Deno.env.get("SUPABASE_URL")!;
  const supabaseAnonKey = Deno.env.get("SUPABASE_ANON_KEY")!;
  const client = createClient(supabaseUrl, supabaseAnonKey, {
    global: { headers: { Authorization: authHeader } },
  });

  const { data, error } = await client.auth.getUser(token);
  return !error && !!data?.user;
}

// ─── Retry helper ──────────────────────────────────────────────────────────
async function withRetry<T>(
  fn: () => Promise<T>,
  retries = MAX_RETRIES,
  delayMs = RETRY_DELAY_MS,
): Promise<T> {
  let lastError: unknown;
  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      return await fn();
    } catch (err) {
      lastError = err;
      if (attempt < retries) {
        await new Promise((r) => setTimeout(r, delayMs * Math.pow(2, attempt)));
      }
    }
  }
  throw lastError;
}

// ─── OpenAI embedding call ─────────────────────────────────────────────────
async function callOpenAIEmbeddings(
  texts: string[],
  model: string,
  dimensions?: number,
): Promise<{ vectors: number[][]; totalTokens: number }> {
  const apiKey = Deno.env.get("OPENAI_API_KEY");
  if (!apiKey) throw new Error("OPENAI_API_KEY not configured");

  const body: Record<string, unknown> = {
    model,
    input: texts,
  };
  if (dimensions) body.dimensions = dimensions;

  const response = await withRetry(async () => {
    const res = await fetch(`${OPENAI_BASE_URL}/embeddings`, {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(body),
    });

    if (!res.ok) {
      const errText = await res.text();
      throw new Error(`OpenAI embeddings error ${res.status}: ${errText}`);
    }

    return res;
  });

  const json = await response.json();

  if (!json.data || !Array.isArray(json.data)) {
    throw new Error("Unexpected response format from OpenAI embeddings");
  }

  // Sort by index to preserve order
  const sorted = [...json.data].sort((a: { index: number }, b: { index: number }) => a.index - b.index);
  const vectors = sorted.map((d: { embedding: number[] }) => d.embedding);
  const totalTokens: number = json.usage?.total_tokens ?? 0;

  return { vectors, totalTokens };
}

// ─── Main handler ──────────────────────────────────────────────────────────
serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  // Auth
  const authed = await authenticate(req);
  if (!authed) {
    return new Response(JSON.stringify({ error: "Unauthorized" }), {
      status: 401,
      headers: { ...corsHeaders, "Content-Type": "application/json" },
    });
  }

  try {
    const { texts, model, dimensions } = await req.json();

    // ── Validation ─────────────────────────────────────────────────────────
    if (!Array.isArray(texts) || texts.length === 0) {
      return new Response(
        JSON.stringify({ error: "texts must be a non-empty array" }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } },
      );
    }

    if (texts.length > MAX_BATCH_SIZE) {
      return new Response(
        JSON.stringify({ error: `Batch too large. Max ${MAX_BATCH_SIZE} texts.` }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } },
      );
    }

    const invalidIdx = texts.findIndex(
      (t) => typeof t !== "string" || t.trim().length === 0,
    );
    if (invalidIdx !== -1) {
      return new Response(
        JSON.stringify({ error: `texts[${invalidIdx}] is empty or not a string` }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } },
      );
    }

    const tooLongIdx = texts.findIndex((t) => t.length > MAX_CHARS_PER_TEXT);
    if (tooLongIdx !== -1) {
      return new Response(
        JSON.stringify({
          error: `texts[${tooLongIdx}] exceeds max ${MAX_CHARS_PER_TEXT} chars`,
        }),
        { status: 400, headers: { ...corsHeaders, "Content-Type": "application/json" } },
      );
    }

    const resolvedModel = model ?? Deno.env.get("EMBEDDING_MODEL") ?? DEFAULT_MODEL;

    // Log counts only — never raw text
    console.log(
      `[embeddings-generate] batch=${texts.length} model=${resolvedModel}${dimensions ? ` dims=${dimensions}` : ""}`,
    );

    const { vectors, totalTokens } = await callOpenAIEmbeddings(
      texts,
      resolvedModel,
      dimensions,
    );

    console.log(
      `[embeddings-generate] done vectors=${vectors.length} tokens=${totalTokens}`,
    );

    return new Response(
      JSON.stringify({
        vectors,
        model: resolvedModel,
        usage: { total_tokens: totalTokens },
      }),
      { headers: { ...corsHeaders, "Content-Type": "application/json" } },
    );
  } catch (err) {
    const message = err instanceof Error ? err.message : "Unknown error";
    console.error("[embeddings-generate] error:", message);
    return new Response(
      JSON.stringify({ error: message }),
      { status: 500, headers: { ...corsHeaders, "Content-Type": "application/json" } },
    );
  }
});
